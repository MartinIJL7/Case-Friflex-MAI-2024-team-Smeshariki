{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ys5hbvScrYI",
        "outputId": "f67d77b0-c7d9-417d-f0b6-1d67956d645d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless  # Используйте headless версию OpenCV, если стандартная вызывает проблемы в Colab\n",
        "import cv2\n",
        "import numpy as np\n",
        "from moviepy.editor import VideoFileClip\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eI5FCLmYxy6",
        "outputId": "5149d241-506a-4ef5-c16f-3381824c5d0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XwognS0aYwHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433c2faf-c10a-47c2-9381-f2187a223ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video saved successfully\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import cv2\n",
        "from PIL import ImageFont, ImageDraw, Image\n",
        "import numpy as np\n",
        "\n",
        "def load_text_from_json(json_path):\n",
        "    with open(json_path, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "    return data['comment']\n",
        "\n",
        "def split_text(text, words_per_fragment=3):\n",
        "    words = text[0].split()\n",
        "    return [' '.join(words[i:i + words_per_fragment]) for i in range(0, len(words), words_per_fragment)]\n",
        "\n",
        "def add_text_effects(frame, text, position, font_path, font_size):\n",
        "    img_pil = Image.fromarray(frame)\n",
        "    draw = ImageDraw.Draw(img_pil)\n",
        "    font = ImageFont.truetype(font_path, font_size)\n",
        "    shadow_color = 'gray'\n",
        "    outline_color = 'black'\n",
        "    text_color = 'white'\n",
        "    x, y = position\n",
        "    shadow_offset = 0\n",
        "    draw.text((x + shadow_offset, y + shadow_offset), text, font=font, fill=shadow_color)\n",
        "    outline_range = 1\n",
        "    for dx in range(-outline_range, outline_range + 1):\n",
        "        for dy in range(-outline_range, outline_range + 1):\n",
        "            if dx != 0 or dy != 0:\n",
        "                draw.text((x + dx, y + dy), text, font=font, fill=outline_color)\n",
        "    draw.text(position, text, font=font, fill=text_color)\n",
        "    return np.array(img_pil)\n",
        "\n",
        "def add_text_to_video(video_path, output_path, json_path, font_path, words_per_fragment=5, rotate='clockwise'):\n",
        "    text = load_text_from_json(json_path)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error opening video stream or file\")\n",
        "        return\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    ret, sample_frame = cap.read()\n",
        "    if rotate == 'clockwise':\n",
        "        sample_frame = cv2.rotate(sample_frame, cv2.ROTATE_90_CLOCKWISE)\n",
        "    elif rotate == 'counterclockwise':\n",
        "        sample_frame = cv2.rotate(sample_frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (sample_frame.shape[1], sample_frame.shape[0]))\n",
        "\n",
        "    fragments = split_text(text, words_per_fragment)\n",
        "    total_fragments = len(fragments)\n",
        "    frames_per_fragment = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) / total_fragments)\n",
        "    current_fragment_index = 0\n",
        "    frame_count = 0\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset frame position after sample\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if rotate == 'clockwise':\n",
        "            frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "        elif rotate == 'counterclockwise':\n",
        "            frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "\n",
        "        current_fragment = fragments[current_fragment_index]\n",
        "        frame_with_text = add_text_effects(frame, current_fragment, (50, 50), font_path, 20)\n",
        "        out.write(frame_with_text)\n",
        "        frame_count += 1\n",
        "        if frame_count % frames_per_fragment == 0 and current_fragment_index < total_fragments - 1:\n",
        "            current_fragment_index += 1\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(\"Video saved successfully\")\n",
        "\n",
        "# Пути и параметры\n",
        "video_path = '/content/final_combination_3.mp4'\n",
        "output_path = '/content/output_video.mp4'\n",
        "json_path = '/content/combined_output (2).json'  # JSON файл с текстом\n",
        "font_path = '/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf'\n",
        "add_text_to_video(video_path, output_path, json_path, font_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import cv2\n",
        "from PIL import ImageFont, ImageDraw, Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_text_from_json(json_path):\n",
        "    with open(json_path, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "    comment = data['comment']\n",
        "    # Обработка случая, когда комментарий является списком\n",
        "    if isinstance(comment, list):\n",
        "        comment = ' '.join(comment)  # Объединение списка в одну строку\n",
        "    return comment\n",
        "\n",
        "def split_text(text, words_per_fragment=3):\n",
        "    words = text.split()\n",
        "    return [' '.join(words[i:i + words_per_fragment]) for i in range(0, len(words), words_per_fragment)]\n",
        "\n",
        "def add_text_effects(frame, text, position, font_path, font_size):\n",
        "    img_pil = Image.fromarray(frame)\n",
        "    draw = ImageDraw.Draw(img_pil)\n",
        "    font = ImageFont.truetype(font_path, font_size)\n",
        "    shadow_color = 'gray'\n",
        "    outline_color = 'black'\n",
        "    text_color = 'white'\n",
        "    x, y = position\n",
        "    shadow_offset = 0\n",
        "    draw.text((x + shadow_offset, y + shadow_offset), text, font=font, fill=shadow_color)\n",
        "    outline_range = 1\n",
        "    for dx in range(-outline_range, outline_range + 1):\n",
        "        for dy in range(-outline_range, outline_range + 1):\n",
        "            if dx != 0 or dy != 0:\n",
        "                draw.text((x + dx, y + dy), text, font=font, fill=outline_color)\n",
        "    draw.text(position, text, font=font, fill=text_color)\n",
        "    return np.array(img_pil)\n",
        "\n",
        "def add_text_to_video(video_path, output_path, json_path, font_path, words_per_fragment=5, rotate='clockwise'):\n",
        "    text = load_text_from_json(json_path)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error opening video stream or file\")\n",
        "        return\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    ret, sample_frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Error: Cannot read video file\")\n",
        "        return\n",
        "\n",
        "    if rotate == 'clockwise':\n",
        "        sample_frame = cv2.rotate(sample_frame, cv2.ROTATE_90_CLOCKWISE)\n",
        "    elif rotate == 'counterclockwise':\n",
        "        sample_frame = cv2.rotate(sample_frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (sample_frame.shape[1], sample_frame.shape[0]))\n",
        "\n",
        "    fragments = split_text(text, words_per_fragment)\n",
        "    total_fragments = len(fragments)\n",
        "    frames_per_fragment = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) / total_fragments)\n",
        "    current_fragment_index = 0\n",
        "    frame_count = 0\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset frame position after sample\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if rotate == 'clockwise':\n",
        "            frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
        "        elif rotate == 'counterclockwise':\n",
        "            frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "\n",
        "        current_fragment = fragments[current_fragment_index]\n",
        "        frame_with_text = add_text_effects(frame, current_fragment, (50, 50), font_path, 30, frame.shape[1])\n",
        "        out.write(frame_with_text)\n",
        "        frame_count += 1\n",
        "        if frame_count % frames_per_fragment == 0 and current_fragment_index < total_fragments - 1:\n",
        "            current_fragment_index += 1\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(\"Video saved successfully\")\n",
        "    # Пути и параметры\n",
        "video_path = '/content/final_combination_3.mp4'\n",
        "output_path = '/content/output_video.mp4'\n",
        "json_path = '/content/combined_output (2).json'  # JSON файл с текстом\n",
        "font_path = '/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf'\n",
        "add_text_to_video(video_path, output_path, json_path, font_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "3snEVT__p9wy",
        "outputId": "fc0f284c-63a0-4b12-e36b-1254081d6ba4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "add_text_effects() takes 5 positional arguments but 6 were given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-476d80523fe5>\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mjson_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/combined_output (2).json'\u001b[0m  \u001b[0;31m# JSON файл с текстом\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mfont_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0madd_text_to_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-476d80523fe5>\u001b[0m in \u001b[0;36madd_text_to_video\u001b[0;34m(video_path, output_path, json_path, font_path, words_per_fragment, rotate)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mcurrent_fragment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfragments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_fragment_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mframe_with_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_text_effects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_fragment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_with_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mframe_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: add_text_effects() takes 5 positional arguments but 6 were given"
          ]
        }
      ]
    }
  ]
}